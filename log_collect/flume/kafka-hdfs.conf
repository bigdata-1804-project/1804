# 测试命令 /opt/apps/flume/bin/flume-ng agent -n a1 -c /opt/apps/flume/conf -f /opt/apps/flume/config/kafka-hdfs.conf -Dflume.root.logger=INFO,console
# 后台运行 nohup /opt/apps/flume/bin/flume-ng agent -n a1 -c /opt/apps/flume/conf -f /opt/apps/flume/config/kafka-hdfs.conf 1>/dev/null 2>/dev/null &


a1.sources = r1
a1.sinks = k1
a1.channels = c1

## sources config
a1.sources.r1.type = org.apache.flume.source.kafka.KafkaSource
a1.sources.r1.channels =c1
a1.sources.r1.batchSize = 5000
a1.sources.r1.batchDurationMillis = 2000
#kafka 节点地址
a1.sources.r1.kafka.bootstrap.servers =192.168.80.91:9092,192.168.80.92:9092,192.168.80.93:9092
a1.sources.r1.kafka.topics = event_log
#这里需要修改
a1.sources.r1.kafka.consumer.group.id = cbg1804


## channels config
a1.channels.c1.type = memory
#内存channel 最大能存放多少byte数据
a1.channels.c1.byteCapacity = 12800000000
#内存channel 最多能存放多少条数据
a1.channels.c1.capacity = 100000000
#内存channel 最大传输多少条数据
a1.channels.c1.transactionCapacity = 10000000
#使用多少内存来存放数据
a1.channels.c1.byteCapacityBufferPercentage = 60
a1.channels.c1.keep-alive = 60

#sinks config
a1.sinks.k1.type = hdfs
a1.sinks.k1.channel = c1
#这里需要修改
a1.sinks.k1.hdfs.path = hdfs://mini1:9000/logs/%Y/%m/%d
a1.sinks.k1.hdfs.fileType = DataStream
a1.sinks.k1.hdfs.filePrefix = daoke360_%H
a1.sinks.k1.hdfs.fileSuffix=.log
a1.sinks.k1.hdfs.minBlockReplicas=1
#每隔多少秒将正在写入的文件进行重名了（滚动）
a1.sinks.k1.hdfs.rollInterval=60
#当正在写入的文件达到多少byte数据就滚动一次，如果配置为0 ，说明这个配置项不起作用
a1.sinks.k1.hdfs.rollSize=0
##当正在写入的文件达到多少条就滚动一次，如果配置为0 ，说明这个配置项不起作用
a1.sinks.k1.hdfs.rollCount=0
#每次最大写多少条数据
a1.sinks.k1.hdfs.batchSize = 100
#使用本地系统时间
a1.sinks.k1.hdfs.useLocalTimeStamp = true

